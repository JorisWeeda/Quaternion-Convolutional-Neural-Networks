{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QXmP5W3Gr0j","executionInfo":{"status":"ok","timestamp":1681669155594,"user_tz":-120,"elapsed":13556,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}},"outputId":"37981c91-2f42-4e27-e38f-f43556c669f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.9.16\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cifar10\n","  Downloading cifar10-1.0.0-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from cifar10) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from cifar10) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from cifar10) (2.27.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->cifar10) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->cifar10) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->cifar10) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->cifar10) (1.26.15)\n","Installing collected packages: cifar10\n","Successfully installed cifar10-1.0.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (1.10.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.9/dist-packages (from imageio) (8.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks\n","  Cloning https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks to /tmp/pip-req-build-we8ykjyv\n","  Running command git clone --filter=blob:none --quiet https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks /tmp/pip-req-build-we8ykjyv\n","  Resolved https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks to commit 28caa7cde240e354fd7b87280450fd233cd494c3\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: Pytorch-QNN\n","  Building wheel for Pytorch-QNN (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Pytorch-QNN: filename=Pytorch_QNN-1-py3-none-any.whl size=21507 sha256=81a7b7a1a945b45f96418dc4212a2675d80a8ce0b2e241321ae3dbcaacedcf97\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wiawi2os/wheels/4d/ef/23/2dab0a09f3d2ba797d554a613cf4d367a6da42f613ca046eed\n","Successfully built Pytorch-QNN\n","Installing collected packages: Pytorch-QNN\n","Successfully installed Pytorch-QNN-1\n"]}],"source":["# run this cell to download the right packages (only needed once)\n","!python --version\n","\n","!pip install cifar10\n","!pip install imageio numpy scipy    \n","!pip install git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks"]},{"cell_type":"code","source":["import time\n","import torch\n","\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from pathlib import Path\n","from torch.utils.data import DataLoader\n","from torchsummary import summary\n","from torchvision import datasets, transforms\n","\n","from core_qnn.quaternion_layers import QuaternionConv, QuaternionLinear\n","from core_qnn.quaternion_ops import check_input, q_normalize\n","\n","device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"],"metadata":{"id":"utugAreOGteM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","# import and download the CIFAR10 dataset\n","transform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n","transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5,.5,.5),(.5,.5,.5))])\n","\n","train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vOREz-aGtpI","executionInfo":{"status":"ok","timestamp":1681669171137,"user_tz":-120,"elapsed":8975,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}},"outputId":"ef939462-e468-46f3-bc40-a8afed4e8d8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 69836548.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","CPU times: user 3.55 s, sys: 1 s, total: 4.55 s\n","Wall time: 9.69 s\n"]}]},{"cell_type":"code","source":["class QuaternionLin(nn.Module):\n","  \"\"\"Reproduction class of the quaternion linear layer.\"\"\"\n","  \n","  def __init__(self, in_channels, out_channels, dimension=2, bias=True):\n","    \"\"\"Create the quaterion linear layer.\"\"\"\n","    super(QuaternionLin, self).__init__()\n","\n","    self.in_channels = np.floor_divide(in_channels, 4)\n","    self.out_channels = np.floor_divide(out_channels, 4)\n","\n","    self.weight_shape = self.get_weight_shape(self.in_channels, self.out_channels)\n","    self._weights = self.weight_tensors(self.weight_shape)\n","\n","    self.r_weight, self.k_weight, self.i_weight, self.j_weight = self._weights\n","\n","    if bias:\n","      self.bias = nn.Parameter(torch.Tensor(out_channels))\n","      nn.init.constant_(self.bias, 0)\n","\n","  def forward(self, input_x):\n","    \"\"\"Apply forward pass of input through quaternion linear layer.\"\"\"\n","    cat_kernels_4_r = torch.cat([self.r_weight, -self.i_weight, -self.j_weight, -self.k_weight], dim=0)\n","    cat_kernels_4_i = torch.cat([self.i_weight,  self.r_weight, -self.k_weight, self.j_weight], dim=0)\n","    cat_kernels_4_j = torch.cat([self.j_weight,  self.k_weight, self.r_weight, -self.i_weight], dim=0)\n","    cat_kernels_4_k = torch.cat([self.k_weight,  -self.j_weight, self.i_weight, self.r_weight], dim=0)\n","\n","    cat_kernels_4_quaternion   = torch.cat([cat_kernels_4_r, cat_kernels_4_i, cat_kernels_4_j, cat_kernels_4_k], dim=1)\n","\n","    if self.bias is not None:\n","      return torch.addmm(self.bias, input_x, cat_kernels_4_quaternion)\n","\n","    return torch.matmul(input_x, cat_kernels_4_quaternion)\n","\n","  @staticmethod\n","  def weight_tensors(weight_shape):\n","    \"\"\"Create and initialise the weight tensors according to quaternion rules.\"\"\"\n","    modulus = nn.Parameter(torch.Tensor(*weight_shape))\n","    modulus = nn.init.xavier_uniform_(modulus, gain=1.0)\n","\n","    i_weight = 2.0 * torch.rand(*weight_shape) - 1.0\n","    j_weight = 2.0 * torch.rand(*weight_shape) - 1.0\n","    k_weight = 2.0 * torch.rand(*weight_shape) - 1.0\n","\n","    sum_imaginary_parts = i_weight.abs() + j_weight.abs() + k_weight.abs()\n","\n","    i_weight = torch.div(i_weight, sum_imaginary_parts)\n","    j_weight = torch.div(j_weight, sum_imaginary_parts)\n","    k_weight = torch.div(k_weight, sum_imaginary_parts)\n","\n","    phase = torch.rand(*weight_shape) * (2 * torch.tensor([np.pi])) - torch.tensor([np.pi])\n","\n","    r_weight = modulus * np.cos(phase)\n","    i_weight = modulus * i_weight * np.sin(phase)\n","    j_weight = modulus * j_weight * np.sin(phase)\n","    k_weight = modulus * k_weight * np.sin(phase)\n","\n","    return nn.Parameter(r_weight), nn.Parameter(i_weight), nn.Parameter(j_weight), nn.Parameter(k_weight)\n","\n","  @staticmethod\n","  def get_weight_shape(in_channels, out_channels):\n","    \"\"\"Construct weight shape based on the input/output channels.\"\"\"\n","    return (in_channels, out_channels)\n","\n","  def __repr__(self):\n","      return self.__class__.__name__ + '(' \\\n","          + 'in_channels='      + str(self.in_channels) \\\n","          + ', out_channels='   + str(self.out_channels) + ')'\n"],"metadata":{"id":"RMYS8igQGtwi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","class CustomQCNN(nn.Module):\n","  \"\"\"Reproduction QCNN to validate quaternion convolution layer.\"\"\"\n","\n","  def __init__(self, in_channels, hidden_channels, out_features, kernel_size):\n","    super(CustomQCNN, self).__init__()\n","\n","    self.conv_1 = QuaternionConv(in_channels, hidden_channels[0], kernel_size, 1)\n","    self.conv_2 = QuaternionConv(hidden_channels[0], hidden_channels[1], kernel_size, 1)\n","\n","    self.pool_1 = nn.MaxPool2d(2, 2)\n","    self.dropout_1 = nn.Dropout(0.25)\n","\n","    self.conv_3 = QuaternionConv(hidden_channels[1], hidden_channels[2], kernel_size, 1)\n","    self.conv_4 = QuaternionConv(hidden_channels[2], hidden_channels[3], kernel_size, 1)\n","\n","    self.pool_2 = nn.MaxPool2d(2, 2)\n","    self.dropout_2 = nn.Dropout(0.25)\n","\n","    self.fc_1 = QuaternionLin(12800, 512)\n","    self.fc_2 = nn.Linear(512, out_features)\n","\n","    self.dropout_3 = nn.Dropout(0.5)\n","    self.sm = nn.Softmax(dim=1)\n","\n","  def forward(self, x):\n","    x = F.relu(self.conv_1(x))\n","    x = F.relu(self.conv_2(x))\n","    x = self.pool_1(x)\n","    x = self.dropout_1(x)\n","\n","    x = F.relu(self.conv_3(x))\n","    x = F.relu(self.conv_4(x))\n","    x = self.pool_2(x)\n","    x = self.dropout_2(x)\n","\n","    x = torch.flatten(x, start_dim=1) \n","\n","    x = F.relu(self.fc_1(x))\n","    x = self.dropout_3(x)\n","    x = self.fc_2(x)\n","    x = self.sm(x)\n","\n","    return x\n","\n","# Model parameters\n","in_channels = 4\n","hidden_channels = [64, 128, 256, 512]\n","out_features = 10\n","kernel_size = (3, 3)\n","\n","batch_size = 32\n","\n","custom_qcnn = CustomQCNN(in_channels, hidden_channels, out_features, kernel_size)\n","custom_qcnn = custom_qcnn.cuda()\n","\n","print(\"Number of trainable parameters: \", sum(p.numel() for p in custom_qcnn.parameters() if p.requires_grad))\n","summary(custom_qcnn, input_size=(in_channels, 32, 32), batch_size=batch_size, device=device.type)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jgK4iik1G3uU","executionInfo":{"status":"ok","timestamp":1681669173243,"user_tz":-120,"elapsed":1917,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}},"outputId":"2e99a7eb-c421-44a2-b4fc-d4fbff07f1c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters:  2032650\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","    QuaternionConv-1           [32, 64, 30, 30]              64\n","    QuaternionConv-2          [32, 128, 28, 28]             128\n","         MaxPool2d-3          [32, 128, 14, 14]               0\n","           Dropout-4          [32, 128, 14, 14]               0\n","    QuaternionConv-5          [32, 256, 12, 12]             256\n","    QuaternionConv-6          [32, 512, 10, 10]             512\n","         MaxPool2d-7            [32, 512, 5, 5]               0\n","           Dropout-8            [32, 512, 5, 5]               0\n","     QuaternionLin-9                  [32, 512]             512\n","          Dropout-10                  [32, 512]               0\n","           Linear-11                   [32, 10]           5,130\n","          Softmax-12                   [32, 10]               0\n","================================================================\n","Total params: 6,602\n","Trainable params: 5,130\n","Non-trainable params: 1,472\n","----------------------------------------------------------------\n","Input size (MB): 0.50\n","Forward/backward pass size (MB): 78.82\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 79.34\n","----------------------------------------------------------------\n","CPU times: user 596 ms, sys: 237 ms, total: 832 ms\n","Wall time: 2.03 s\n"]}]},{"cell_type":"code","source":["%%time\n","paper_qcnn_lin_layer = QuaternionLinear(12800, 512)\n","\n","print(\"Number of trainable parameters: \", sum(p.numel() for p in paper_qcnn_lin_layer.parameters() if p.requires_grad))\n","paper_qcnn_lin_layer.i_weight[0][:50]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PwYhc7VSMnA","executionInfo":{"status":"ok","timestamp":1681669176167,"user_tz":-120,"elapsed":2932,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}},"outputId":"345f0cf7-dec8-466d-a965-919d3cefdc25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters:  1638912\n","CPU times: user 2.46 s, sys: 4.87 ms, total: 2.46 s\n","Wall time: 2.53 s\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([-9.8619e-03,  1.7768e-02, -3.9290e-03, -8.4551e-03, -9.6563e-03,\n","         6.3405e-03, -9.6673e-03, -8.2083e-03,  1.0748e-02,  1.6635e-03,\n","         7.7834e-03, -1.8080e-02,  2.0989e-04, -1.2731e-02, -6.1434e-03,\n","        -8.1282e-03,  1.1271e-02, -1.2184e-02,  1.2324e-03,  1.0997e-02,\n","        -4.6240e-03,  1.9024e-02,  3.5174e-03,  7.7954e-03,  6.4949e-03,\n","         2.2042e-02, -1.5830e-03, -1.0838e-02, -5.8510e-03,  3.0616e-03,\n","        -6.7673e-03, -1.7402e-02, -9.4927e-03, -1.1655e-02, -4.9278e-04,\n","         7.3662e-04, -1.3883e-02, -9.8667e-06,  9.0085e-03,  2.5610e-03,\n","        -9.9933e-03, -1.7828e-03,  6.2730e-03, -4.0444e-03, -7.5603e-04,\n","        -6.5449e-03, -2.2364e-03,  8.6866e-04, -3.7308e-04,  1.2813e-02],\n","       grad_fn=<SliceBackward0>)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["%%time\n","custom_qcnn_lin_layer = QuaternionLin(12800, 512)\n","\n","print(\"Number of trainable parameters: \", sum(p.numel() for p in custom_qcnn_lin_layer.parameters() if p.requires_grad))\n","custom_qcnn_lin_layer.i_weight[0][:50]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DhsKbxSASb6y","executionInfo":{"status":"ok","timestamp":1681669176168,"user_tz":-120,"elapsed":31,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}},"outputId":"a64af330-71e6-4e99-a935-bd31d7f23b2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters:  1638912\n","CPU times: user 31.7 ms, sys: 0 ns, total: 31.7 ms\n","Wall time: 31.7 ms\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([ 4.2403e-05, -3.0373e-03,  2.4217e-04,  1.2262e-02,  4.8097e-04,\n","         3.4563e-04,  1.0125e-02,  4.6110e-05, -4.4688e-03,  2.1976e-03,\n","        -1.1161e-02,  1.7865e-03,  2.6552e-04, -2.0037e-03,  7.9006e-03,\n","         5.3779e-03, -5.1694e-03, -3.0157e-03,  9.0666e-03,  5.5432e-04,\n","         1.8890e-04, -2.3435e-03,  1.7509e-02,  3.2966e-03, -3.0224e-03,\n","        -7.9977e-04, -4.0333e-03,  1.6774e-03, -1.7125e-03,  4.8665e-04,\n","        -1.2629e-04,  3.5356e-03, -1.4928e-02,  1.4676e-02, -1.2352e-04,\n","        -3.9960e-03,  6.0097e-03, -2.1924e-04, -7.7298e-03,  9.5267e-04,\n","        -5.3146e-03, -3.2860e-03,  7.6674e-03,  4.6479e-03, -2.3704e-03,\n","         1.2056e-04,  8.2204e-03,  3.5477e-04, -6.8082e-03, -3.2168e-03],\n","       grad_fn=<SliceBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%%time\n","num_epochs = 80\n","amount_of_trainings = 3\n","\n","learning_rate = 0.0001\n","learning_rate_decay = 1e-6\n","\n","batch_size = 32\n","\n","custom_qcnn_accs = []\n","trainings_seed_excution_time = []\n","\n","for training_seed in range(amount_of_trainings):\n","  print(f'Start training seed {training_seed + 1}')\n","  start_time_training_seed = time.time()\n","\n","  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n","  test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","  custom_qcnn = CustomQCNN(in_channels, hidden_channels, out_features, kernel_size)\n","  custom_qcnn = custom_qcnn.cuda()\n","\n","  optimizer = torch.optim.RMSprop(custom_qcnn.parameters(),lr=learning_rate, weight_decay=learning_rate_decay)\n","  criterion = nn.CrossEntropyLoss()\n","\n","  for epoch in range(1, num_epochs):\n","    \n","    custom_qcnn.train()\n","\n","    for index, (x_batch, y_batch) in enumerate(train_loader):\n","      zeros_channel = torch.zeros((x_batch.shape[0], 1, x_batch.shape[2], x_batch.shape[3]))\n","      x_batch = torch.cat([x_batch, zeros_channel], dim=1)\n","\n","      # Check if the input size is correct\n","      check_input(x_batch)\n","\n","      x_batch = x_batch.cuda()\n","      y_batch = y_batch.cuda()\n","      \n","      # Perform forward pass\n","      y_pred = custom_qcnn(x_batch)\n","\n","      # Compute the loss\n","      loss = criterion(y_pred, y_batch)\n","\n","      # Backpropagation\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","    if (epoch / 10).is_integer():\n","      print (f'Epoch [{epoch + 1}/{num_epochs}], Last loss: {loss.item():.4f}')\n","\n","  with torch.no_grad():\n","      n_correct = 0\n","      n_samples = 0\n","\n","      custom_qcnn.eval()\n","\n","      for index, (x_batch, y_batch) in enumerate(test_loader):\n","        zeros_channel = torch.zeros((x_batch.shape[0], 1, x_batch.shape[2], x_batch.shape[3]))\n","        x_batch = torch.cat([x_batch, zeros_channel], dim=1)\n","\n","        x_batch = x_batch.cuda()\n","        y_batch = y_batch.cuda()\n","\n","        # Check if the input size is correct\n","        check_input(x_batch)\n","\n","        # Perform forward pass\n","        y_pred = custom_qcnn(x_batch)\n","\n","        _, predicted = torch.max(y_pred,1)\n","        n_samples += y_batch.size(0)\n","        n_correct += (predicted == y_batch).sum().item()\n","\n","      acc = 100 * n_correct / n_samples\n","      custom_qcnn_accs.append(acc)\n","  \n","  elapsed_training_time = int(time.time() - start_time_training_seed)\n","  trainings_seed_excution_time.append(start_time_training_seed)\n","\n","  print(f'Finished training seed {training_seed + 1}, accuracy of the network: {acc}%, elapsed time: {elapsed_training_time} sec')\n","\n","print(f'Average accuracy over {amount_of_trainings}, {num_epochs} epochs each results in: {sum(custom_qcnn_accs) / amount_of_trainings}')"],"metadata":{"id":"IYnxL4TYG4CB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bec4c795-45fc-4684-ceb8-b95eafbe0368","executionInfo":{"status":"ok","timestamp":1681674450111,"user_tz":-120,"elapsed":5273963,"user":{"displayName":"joris weeda","userId":"16756172332098140791"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start training seed 1\n","Epoch [11/80], Last loss: 1.9361\n","Epoch [21/80], Last loss: 1.6766\n","Epoch [31/80], Last loss: 1.5703\n","Epoch [41/80], Last loss: 1.8227\n","Epoch [51/80], Last loss: 1.5918\n","Epoch [61/80], Last loss: 1.5288\n","Epoch [71/80], Last loss: 1.6498\n","Finished training seed 1, accuracy of the network: 76.81%, elapsed time: 1778 sec\n","Start training seed 2\n","Epoch [11/80], Last loss: 1.7154\n","Epoch [21/80], Last loss: 1.7754\n","Epoch [31/80], Last loss: 1.5692\n","Epoch [41/80], Last loss: 1.5782\n","Epoch [51/80], Last loss: 1.6479\n","Epoch [61/80], Last loss: 1.4617\n","Epoch [71/80], Last loss: 1.5288\n","Finished training seed 2, accuracy of the network: 78.19%, elapsed time: 1747 sec\n","Start training seed 3\n","Epoch [11/80], Last loss: 1.6538\n","Epoch [21/80], Last loss: 1.7058\n","Epoch [31/80], Last loss: 1.5524\n","Epoch [41/80], Last loss: 1.6071\n","Epoch [51/80], Last loss: 1.5236\n","Epoch [61/80], Last loss: 1.5637\n","Epoch [71/80], Last loss: 1.5399\n","Finished training seed 3, accuracy of the network: 78.02%, elapsed time: 1747 sec\n","Average accuracy over 3, 80 epochs each results in: 77.67333333333333\n","CPU times: user 57min 26s, sys: 2min 57s, total: 1h 24s\n","Wall time: 1h 27min 53s\n"]}]}]}